{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_nolink</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text_nomentions</th>\n",
       "      <th>extracted_locations</th>\n",
       "      <th>noPunctuations</th>\n",
       "      <th>noStopwordsTokenized</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>all_locations</th>\n",
       "      <th>extra_keywords</th>\n",
       "      <th>all_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>['earthquake']</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Our Deeds are the Reason of this earthquake Ma...</td>\n",
       "      <td>['Our', 'Deeds', 'Reason', 'earthquake', 'May'...</td>\n",
       "      <td>['Our', 'Deeds', 'Reason', 'earthquake', 'May'...</td>\n",
       "      <td>our deeds reason earthquake may allah forgive u</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['earthquake']</td>\n",
       "      <td>earthquake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>[]</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>['Canada']</td>\n",
       "      <td>Forest fire near La Ronge Sask Canada</td>\n",
       "      <td>['Forest', 'fire', 'near', 'La', 'Ronge', 'Sas...</td>\n",
       "      <td>['Forest', 'fire', 'near', 'La', 'Ronge', 'Sas...</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>Canada</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>All residents asked to shelter in place are be...</td>\n",
       "      <td>['All', 'residents', 'asked', 'shelter', 'plac...</td>\n",
       "      <td>['All', 'resident', 'asked', 'shelter', 'place...</td>\n",
       "      <td>all resident asked shelter place notified offi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>['wildfires']</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>['California']</td>\n",
       "      <td>13000 people receive wildfires evacuation orde...</td>\n",
       "      <td>['13000', 'people', 'receive', 'wildfires', 'e...</td>\n",
       "      <td>['13000', 'people', 'receive', 'wildfire', 'ev...</td>\n",
       "      <td>13000 people receive wildfire evacuation order...</td>\n",
       "      <td>California</td>\n",
       "      <td>['wildfires']</td>\n",
       "      <td>wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>['Alaska', 'wildfires']</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>['Ruby', 'Alaska']</td>\n",
       "      <td>Just got sent this photo from Ruby Alaska as s...</td>\n",
       "      <td>['Just', 'got', 'sent', 'photo', 'Ruby', 'Alas...</td>\n",
       "      <td>['Just', 'got', 'sent', 'photo', 'Ruby', 'Alas...</td>\n",
       "      <td>just got sent photo ruby alaska smoke wildfire...</td>\n",
       "      <td>Ruby Alaska</td>\n",
       "      <td>['wildfires']</td>\n",
       "      <td>wildfires</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target                                        text_nolink  \\\n",
       "0       1  Our Deeds are the Reason of this #earthquake M...   \n",
       "1       1             Forest fire near La Ronge Sask. Canada   \n",
       "2       1  All residents asked to 'shelter in place' are ...   \n",
       "3       1  13,000 people receive #wildfires evacuation or...   \n",
       "4       1  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "                  hashtags                                    text_nomentions  \\\n",
       "0           ['earthquake']  Our Deeds are the Reason of this #earthquake M...   \n",
       "1                       []             Forest fire near La Ronge Sask. Canada   \n",
       "2                       []  All residents asked to 'shelter in place' are ...   \n",
       "3            ['wildfires']  13,000 people receive #wildfires evacuation or...   \n",
       "4  ['Alaska', 'wildfires']  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "  extracted_locations                                     noPunctuations  \\\n",
       "0                  []  Our Deeds are the Reason of this earthquake Ma...   \n",
       "1          ['Canada']              Forest fire near La Ronge Sask Canada   \n",
       "2                  []  All residents asked to shelter in place are be...   \n",
       "3      ['California']  13000 people receive wildfires evacuation orde...   \n",
       "4  ['Ruby', 'Alaska']  Just got sent this photo from Ruby Alaska as s...   \n",
       "\n",
       "                                noStopwordsTokenized  \\\n",
       "0  ['Our', 'Deeds', 'Reason', 'earthquake', 'May'...   \n",
       "1  ['Forest', 'fire', 'near', 'La', 'Ronge', 'Sas...   \n",
       "2  ['All', 'residents', 'asked', 'shelter', 'plac...   \n",
       "3  ['13000', 'people', 'receive', 'wildfires', 'e...   \n",
       "4  ['Just', 'got', 'sent', 'photo', 'Ruby', 'Alas...   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0  ['Our', 'Deeds', 'Reason', 'earthquake', 'May'...   \n",
       "1  ['Forest', 'fire', 'near', 'La', 'Ronge', 'Sas...   \n",
       "2  ['All', 'resident', 'asked', 'shelter', 'place...   \n",
       "3  ['13000', 'people', 'receive', 'wildfire', 'ev...   \n",
       "4  ['Just', 'got', 'sent', 'photo', 'Ruby', 'Alas...   \n",
       "\n",
       "                                        text_cleaned all_locations  \\\n",
       "0    our deeds reason earthquake may allah forgive u           NaN   \n",
       "1              forest fire near la ronge sask canada        Canada   \n",
       "2  all resident asked shelter place notified offi...           NaN   \n",
       "3  13000 people receive wildfire evacuation order...    California   \n",
       "4  just got sent photo ruby alaska smoke wildfire...   Ruby Alaska   \n",
       "\n",
       "   extra_keywords all_keywords  \n",
       "0  ['earthquake']   earthquake  \n",
       "1              []          NaN  \n",
       "2              []          NaN  \n",
       "3   ['wildfires']    wildfires  \n",
       "4   ['wildfires']    wildfires  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned = pd.read_excel('./data_engineered.xlsx')\n",
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_cleaned[['text_cleaned', 'all_locations', 'all_keywords', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>all_locations</th>\n",
       "      <th>all_keywords</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>our deeds reason earthquake may allah forgive u</td>\n",
       "      <td>NaN</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>Canada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all resident asked shelter place notified offi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13000 people receive wildfire evacuation order...</td>\n",
       "      <td>California</td>\n",
       "      <td>wildfires</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>just got sent photo ruby alaska smoke wildfire...</td>\n",
       "      <td>Ruby Alaska</td>\n",
       "      <td>wildfires</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        text_cleaned all_locations  \\\n",
       "0    our deeds reason earthquake may allah forgive u           NaN   \n",
       "1              forest fire near la ronge sask canada        Canada   \n",
       "2  all resident asked shelter place notified offi...           NaN   \n",
       "3  13000 people receive wildfire evacuation order...    California   \n",
       "4  just got sent photo ruby alaska smoke wildfire...   Ruby Alaska   \n",
       "\n",
       "  all_keywords  target  \n",
       "0   earthquake       1  \n",
       "1          NaN       1  \n",
       "2          NaN       1  \n",
       "3    wildfires       1  \n",
       "4    wildfires       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_length'] = df['text_cleaned'].apply(lambda x:len(x))\n",
    "df['word_count'] = df['text_cleaned'].apply(lambda x:len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text_cleaned        0\n",
       "all_locations    2110\n",
       "all_keywords       41\n",
       "target              0\n",
       "text_length         0\n",
       "word_count          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(\"NA\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text_cleaned     0\n",
       "all_locations    0\n",
       "all_keywords     0\n",
       "target           0\n",
       "text_length      0\n",
       "word_count       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.compose import make_column_transformer\n",
    "cv = CountVectorizer()\n",
    "\n",
    "X = cv.fit_transform(df['text_cleaned']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.c_[X, df['text_length'], df['word_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[630 688]\n",
      " [177 789]]\n",
      "0.6212784588441331\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "classifier1 = GaussianNB()\n",
    "classifier1.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = classifier1.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print(accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1048  270]\n",
      " [ 329  637]]\n",
      "0.7377408056042032\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "treeClassifier1 = DecisionTreeClassifier()\n",
    "treeClassifier1.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = treeClassifier1.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print(accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1205  113]\n",
      " [ 375  591]]\n",
      "0.7863397548161121\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print(accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1132  186]\n",
      " [ 272  694]]\n",
      "0.7994746059544658\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "lr = LogisticRegression(penalty='l2', C=1, max_iter=7600, random_state=42)\n",
    "lr.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = lr.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print(accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1204  114]\n",
      " [ 337  629]]\n",
      "0.8025394045534151\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = bnb.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print(accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lazypredict\n",
    "# from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "# clf = LazyClassifier(verbose=True, ignore_warnings=True)\n",
    "# models, predictions = clf.fit(X_train, X_test, Y_train, Y_test)\n",
    "# models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the data on the given `test.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.read_csv('../nlp-getting-started/test.csv')\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CleanData import CleanData\n",
    "\n",
    "cleanDataobj = CleanData(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>text_nolink</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text_nomentions</th>\n",
       "      <th>extracted_locations</th>\n",
       "      <th>noPunctuations</th>\n",
       "      <th>noStopwordsTokenized</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>all_locations</th>\n",
       "      <th>extra_keywords</th>\n",
       "      <th>all_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>[]</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>[]</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>[Just, happened, terrible, car, crash]</td>\n",
       "      <td>[Just, happened, terrible, car, crash]</td>\n",
       "      <td>just happened terrible car crash</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>[earthquake]</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Heard about earthquake is different cities sta...</td>\n",
       "      <td>[Heard, earthquake, different, cities, stay, s...</td>\n",
       "      <td>[Heard, earthquake, different, city, stay, saf...</td>\n",
       "      <td>heard earthquake different city stay safe ever...</td>\n",
       "      <td></td>\n",
       "      <td>[earthquake]</td>\n",
       "      <td>earthquake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>[]</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>[]</td>\n",
       "      <td>there is a forest fire at spot pond geese are ...</td>\n",
       "      <td>[forest, fire, spot, pond, geese, fleeing, acr...</td>\n",
       "      <td>[forest, fire, spot, pond, goose, fleeing, acr...</td>\n",
       "      <td>forest fire spot pond goose fleeing across str...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>[Spokane, wildfires]</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>[]</td>\n",
       "      <td>Apocalypse lighting Spokane wildfires</td>\n",
       "      <td>[Apocalypse, lighting, Spokane, wildfires]</td>\n",
       "      <td>[Apocalypse, lighting, Spokane, wildfire]</td>\n",
       "      <td>apocalypse lighting spokane wildfire</td>\n",
       "      <td></td>\n",
       "      <td>[Spokane, wildfires]</td>\n",
       "      <td>Spokane wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>[]</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>[China, Taiwan]</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>[Typhoon, Soudelor, kills, 28, China, Taiwan]</td>\n",
       "      <td>[Typhoon, Soudelor, kill, 28, China, Taiwan]</td>\n",
       "      <td>typhoon soudelor kill 28 china taiwan</td>\n",
       "      <td>Taiwan China</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   0      NA       NA                 Just happened a terrible car crash   \n",
       "1   2      NA       NA  Heard about #earthquake is different cities, s...   \n",
       "2   3      NA       NA  there is a forest fire at spot pond, geese are...   \n",
       "3   9      NA       NA           Apocalypse lighting. #Spokane #wildfires   \n",
       "4  11      NA       NA      Typhoon Soudelor kills 28 in China and Taiwan   \n",
       "\n",
       "                                         text_nolink              hashtags  \\\n",
       "0                 Just happened a terrible car crash                    []   \n",
       "1  Heard about #earthquake is different cities, s...          [earthquake]   \n",
       "2  there is a forest fire at spot pond, geese are...                    []   \n",
       "3           Apocalypse lighting. #Spokane #wildfires  [Spokane, wildfires]   \n",
       "4      Typhoon Soudelor kills 28 in China and Taiwan                    []   \n",
       "\n",
       "                                     text_nomentions extracted_locations  \\\n",
       "0                 Just happened a terrible car crash                  []   \n",
       "1  Heard about #earthquake is different cities, s...                  []   \n",
       "2  there is a forest fire at spot pond, geese are...                  []   \n",
       "3           Apocalypse lighting. #Spokane #wildfires                  []   \n",
       "4      Typhoon Soudelor kills 28 in China and Taiwan     [China, Taiwan]   \n",
       "\n",
       "                                      noPunctuations  \\\n",
       "0                 Just happened a terrible car crash   \n",
       "1  Heard about earthquake is different cities sta...   \n",
       "2  there is a forest fire at spot pond geese are ...   \n",
       "3              Apocalypse lighting Spokane wildfires   \n",
       "4      Typhoon Soudelor kills 28 in China and Taiwan   \n",
       "\n",
       "                                noStopwordsTokenized  \\\n",
       "0             [Just, happened, terrible, car, crash]   \n",
       "1  [Heard, earthquake, different, cities, stay, s...   \n",
       "2  [forest, fire, spot, pond, geese, fleeing, acr...   \n",
       "3         [Apocalypse, lighting, Spokane, wildfires]   \n",
       "4      [Typhoon, Soudelor, kills, 28, China, Taiwan]   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0             [Just, happened, terrible, car, crash]   \n",
       "1  [Heard, earthquake, different, city, stay, saf...   \n",
       "2  [forest, fire, spot, pond, goose, fleeing, acr...   \n",
       "3          [Apocalypse, lighting, Spokane, wildfire]   \n",
       "4       [Typhoon, Soudelor, kill, 28, China, Taiwan]   \n",
       "\n",
       "                                        text_cleaned all_locations  \\\n",
       "0                   just happened terrible car crash                 \n",
       "1  heard earthquake different city stay safe ever...                 \n",
       "2  forest fire spot pond goose fleeing across str...                 \n",
       "3               apocalypse lighting spokane wildfire                 \n",
       "4              typhoon soudelor kill 28 china taiwan  Taiwan China   \n",
       "\n",
       "         extra_keywords       all_keywords  \n",
       "0                    []                     \n",
       "1          [earthquake]         earthquake  \n",
       "2                    []                     \n",
       "3  [Spokane, wildfires]  Spokane wildfires  \n",
       "4                    []                     "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestData_cleaned = cleanDataobj.clean()\n",
    "TestData_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col = TestData_cleaned['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestData = TestData_cleaned[['text_cleaned', 'all_locations', 'all_keywords']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestData['text_length'] = TestData['text_cleaned'].apply(lambda x:len(x))\n",
    "TestData['word_count'] = TestData['text_cleaned'].apply(lambda x:len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>all_locations</th>\n",
       "      <th>all_keywords</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>just happened terrible car crash</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>heard earthquake different city stay safe ever...</td>\n",
       "      <td></td>\n",
       "      <td>earthquake</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>forest fire spot pond goose fleeing across str...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>63</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apocalypse lighting spokane wildfire</td>\n",
       "      <td></td>\n",
       "      <td>Spokane wildfires</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>typhoon soudelor kill 28 china taiwan</td>\n",
       "      <td>Taiwan China</td>\n",
       "      <td></td>\n",
       "      <td>37</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        text_cleaned all_locations  \\\n",
       "0                   just happened terrible car crash                 \n",
       "1  heard earthquake different city stay safe ever...                 \n",
       "2  forest fire spot pond goose fleeing across str...                 \n",
       "3               apocalypse lighting spokane wildfire                 \n",
       "4              typhoon soudelor kill 28 china taiwan  Taiwan China   \n",
       "\n",
       "        all_keywords  text_length  word_count  \n",
       "0                              32           5  \n",
       "1         earthquake           50           7  \n",
       "2                              63          11  \n",
       "3  Spokane wildfires           36           4  \n",
       "4                              37           6  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestData.fillna(\"NA\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_X = cv.transform(TestData['text_cleaned']).toarray()\n",
    "Test_X = np.c_[Test_X, TestData['text_length'], TestData['word_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ...,  0, 32,  5],\n",
       "       [ 0,  0,  0, ...,  0, 50,  7],\n",
       "       [ 0,  0,  0, ...,  0, 63, 11],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  0, 29,  4],\n",
       "       [ 0,  0,  0, ...,  0, 39,  6],\n",
       "       [ 0,  0,  0, ...,  0, 57,  6]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# predictionvalues = []\n",
    "# for el in df_test:\n",
    "# Y_pred_test = bnb.predict(Test_X)\n",
    "Y_pred_test = lr.predict(Test_X)\n",
    "print(Y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissionArray = np.c_[id_col, Y_pred_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(submissionArray, columns=['id','target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       1\n",
       "1   2       1\n",
       "2   3       1\n",
       "3   9       1\n",
       "4  11       1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('../../Natural Language Processing with Disaster Tweets/submission2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
